{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fg9zr5VnjOqC"
      },
      "outputs": [],
      "source": [
        "# Import các thư viện cần thiết\n",
        "import nltk # thư viện xử lý ngôn ngữ tiên nhiên\n",
        "from nltk.corpus import stopwords # Module chứa các stop words\n",
        "from nltk.tokenize import word_tokenize # Module tách từ\n",
        "from collections import Counter # Module đếm tần suất xuất hiện của các từ\n",
        "import string # Chứa các ký tự đặc biệt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download tất cả các resource cần thiết\n",
        "nltk.download('punkt') # Tải model tách từ\n",
        "nltk.download('stopwords') # Tải danh sách stopwords\n",
        "nltk.download('punkt_tab') # Tải bảng tham chiếu cho punkt"
      ],
      "metadata": {
        "id": "PqFLmwm1kj12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "  # Bước 1: Chuẩn hóa text về chữ thường\n",
        "  text = text.lower()\n",
        "\n",
        "  # Bước 2: Loại bỏ các dấu câu sử dụng string.puntuation\n",
        "  # str.maketrans tạo bảng mapping để thay thế ký tự\n",
        "  text = text.translate(str.maketrans('','', string.punctuation))\n",
        "\n",
        "  # Bước 3: Tách từ đơn giản bằng khoảng trắng\n",
        "  # split() sẽ tách thành chuỗi các list các từ\n",
        "  tokens = text.split()\n",
        "\n",
        "  # Bước 4: Loại bỏ stop words:\n",
        "  stop_words = set(stopwords.words('english')) # Lấy danh sách stop words tiếng Anh\n",
        "  print(stop_words)\n",
        "  tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "  # Bước 5: Loại bỏ khoảng trắng thừa ở đầu và cuối mỗi từ\n",
        "  tokens = [word.strip() for word in tokens]\n",
        "\n",
        "  return tokens\n"
      ],
      "metadata": {
        "id": "-xNXVerRlVOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text =\"\"\"\n",
        "NLTK is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries, and an active discussion forum.\n",
        "\n",
        "Thanks to a hands-on guide introducing programming fundamentals alongside topics in computational linguistics, plus comprehensive API documentation, NLTK is suitable for linguists, engineers, students, educators, researchers, and industry users alike. NLTK is available for Windows, Mac OS X, and Linux. Best of all, NLTK is a free, open source, community-driven project.\n",
        "\n",
        "NLTK has been called “a wonderful tool for teaching, and working in, computational linguistics using Python,” and “an amazing library to play with natural language.”\n",
        "\n",
        "Natural Language Processing with Python provides a practical introduction to programming for language processing. Written by the creators of NLTK, it guides the reader through the fundamentals of writing Python programs, working with corpora, categorizing text, analyzing linguistic structure, and more. The online version of the book has been been updated for Python 3 and NLTK 3. (The original Python 2 version is still available at\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Pee6eE4_o6Ly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Xử lý văn bản mẫu\n",
        "processed_tokens = preprocess(text)\n",
        "\n",
        "# Tính tần suất xuất hiện của các từ\n",
        "frequency = Counter(processed_tokens)  # Counter sẽ đếm số lần xuất hiện của mỗi từ\n",
        "\n",
        "# In ra 6 từ có tần suất xuất hiện cao nhất\n",
        "print(\"Các từ xuất hiện nhiều nhất:\")\n",
        "for word, count in frequency.most_common(6):  # most_common(n) trả về n từ có tần suất cao nhất\n",
        "    print(f\"{word}: {count}\")"
      ],
      "metadata": {
        "id": "A_ghTLoYow9N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}